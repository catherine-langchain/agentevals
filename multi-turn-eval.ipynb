{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0579d627",
   "metadata": {},
   "source": [
    "# Evaluating Trajectory with AgentEvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6364e8b5-0485-489a-9b28-3a286b957c67",
   "metadata": {},
   "source": [
    "Loading Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfa2a11f-b465-4466-a418-b34446cf6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path=\"./.env\", override=True)\n",
    "\n",
    "model = ChatOpenAI(model=\"o3-mini\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6455c2f2-068d-4548-8d4f-f34ca2ff4e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192cf6c-e74d-48a5-b16e-333ab446f828",
   "metadata": {},
   "source": [
    "## Interacting with a Deployed Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266737ea-03a5-4e79-9b2a-e00d38136e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# SET UP\n",
    "client = get_client(\n",
    "    url=\"https://langgraph-101-agents-927c55fb4bcb5c91a86f1ed4ac544ae3.us.langgraph.app\", headers={\"Authorization\": api_key}\n",
    ")\n",
    "\n",
    "thread = await client.threads.create()\n",
    "assistant_id = \"Store Supervisor\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2abd28-c52c-44ce-be70-7103e9692d06",
   "metadata": {},
   "source": [
    "Building Application Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331592e9-f02f-4114-b6f1-6db2d31223b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openevals.llm import create_async_llm_as_judge\n",
    "from openevals.simulators import run_multiturn_simulation_async, create_llm_simulated_user\n",
    "\n",
    "# Application logic\n",
    "async def app(inputs, thread_id: str):\n",
    "    chunks = []\n",
    "    async for chunk in client.runs.stream(\n",
    "        thread_id=thread['thread_id'],\n",
    "        assistant_id=assistant_id,\n",
    "        input={\"messages\": [inputs]},\n",
    "        stream_mode=\"updates\",\n",
    "    ):\n",
    "        chunks.append(chunk.data)\n",
    "    message = {\"role\": \"assistant\", \"content\": chunks[-1][\"supervisor\"][\"messages\"][-1][\"content\"]}\n",
    "    return message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8ace07-d28a-4646-8e89-23d629834a95",
   "metadata": {},
   "source": [
    "Creating user persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8add60f-e62a-401b-a38f-aa5c99f540e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user persona\n",
    "user = create_llm_simulated_user(\n",
    "    system=\"\"\"You are a user who is frustrated with your most recent purchase, and wants to get a refund. \n",
    "    Your customer id is 30. You don't know about the invoice ID but you know it's the most recent purchase. \n",
    "    Only provide information on your ID after being prompted.\"\"\",\n",
    "    model=\"openai:gpt-4.1-nano\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab95935-02ce-42a0-9be9-4e3f49fc2bd7",
   "metadata": {},
   "source": [
    "Creating evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68aedfcb-7798-49cd-bd5a-1faacdc14c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluators \n",
    "satisfaction_evaluator_async = create_async_llm_as_judge(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    prompt=\"Based on the below conversation, is the user satisfied?\\n{outputs}\",\n",
    "    feedback_key=\"satisfaction\",\n",
    ")\n",
    "\n",
    "resolution_evaluator_async = create_async_llm_as_judge(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    prompt=\"Based on the below conversation, is the user request resolved?\\n{outputs}\",\n",
    "    feedback_key=\"resolution\",\n",
    ")\n",
    "\n",
    "professionalism_evaluator_async = create_async_llm_as_judge(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    prompt=\"Based on the below conversation, has our agent remained a professional tone throughout the conversation?\\n{outputs}\",\n",
    "    feedback_key=\"professionalism\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d271b-9096-437f-9b52-bb6c12d93425",
   "metadata": {},
   "source": [
    "#### Running simulation #1 \n",
    "Stopping with max_turns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ffd6a8b-3203-4a87-8eaa-07150742d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation \n",
    "simulator_result = await run_multiturn_simulation_async(\n",
    "    app=app,\n",
    "    user=user,\n",
    "    trajectory_evaluators=[satisfaction_evaluator_async, resolution_evaluator_async, professionalism_evaluator_async],\n",
    "    max_turns=5,\n",
    "    thread_id=thread[\"thread_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95a23e5a-0cb8-414f-9539-bc62294c7dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I recently made a purchase and I'm really disappointed with it. I'd like to request a refund for my most recent order. Can you assist me with this?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Of course! To assist you with your refund request, could you please provide me with your customer ID or the order details? This will help me locate your purchase information and proceed with the refund process.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Sure, my customer ID is 30. My recent order was not satisfactory, and I would like to proceed with a refund. Please let me know what information you need next.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I have retrieved the details of your most recent purchase. If you would like to proceed with the refund request for this order, please confirm, and I will assist you further.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Yes, I would like to proceed with the refund request for my most recent order. Please let me know the next steps.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The refund process for your most recent purchase has been initiated. Jane, our Sales Support Agent, will be handling your request. You can reach her at jane@chinookcorp.com if you have any questions or need further assistance. Please allow a few business days for the refund to be processed and reflected in your account. If you have any further questions or need additional assistance, feel free to ask!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Thank you for your help. I appreciate the assistance and will contact Jane if I have any further questions.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You're welcome! I'm glad I could assist you. If you have any more questions or need further assistance, feel free to reach out. Have a great day!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Thank you! Have a great day as well.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you! Have a wonderful day, and feel free to reach out if you need any assistance in the future. Take care!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages.utils import convert_to_messages\n",
    "messages = convert_to_messages(simulator_result[\"trajectory\"])\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "881201f1-c408-4c04-aedc-6cd3e31b5c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'satisfaction', 'score': True, 'comment': 'The user expressed dissatisfaction with their purchase and initiated a refund request, which the assistant addressed effectively by providing the necessary steps and the contact information for further assistance. The user thanked the assistant, indicating they were satisfied with the help received and the resolution process. This exchange shows positive engagement and closure, suggesting user satisfaction with the outcome. Thus, the score should be: true.', 'metadata': None}\n",
      "{'key': 'resolution', 'score': True, 'comment': 'The user requested a refund for their recent order, and the assistant successfully guided the user through the necessary steps to initiate the refund process. The user received confirmation that the refund process was started, was provided with contact information for further inquiries, and expressed appreciation for the help they received. Therefore, the userâ€™s request has been resolved. Thus, the score should be: true.', 'metadata': None}\n",
      "{'key': 'professionalism', 'score': True, 'comment': \"The agent consistently maintained a professional tone throughout the conversation. They addressed the user's concerns respectfully, provided necessary information clearly, and offered additional assistance when needed. The responses were polite and structured, demonstrating professionalism. Thus, the score should be: true.\", 'metadata': None}\n"
     ]
    }
   ],
   "source": [
    "for e in simulator_result[\"evaluator_results\"]: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b47eb-6a38-4daa-b372-209dac591c36",
   "metadata": {},
   "source": [
    "#### Running simulation #2\n",
    "Stopping with max_turns or stopping_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3d16f9-c38c-4020-88b6-d9afa9b0cd74",
   "metadata": {},
   "source": [
    "Implementing callable stopping funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cdfbad7-6f2b-45e6-8b77-3834b50d9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "class Condition(BaseModel):\n",
    "    state: bool = Field(description=\"True if stopping condition was met, False if hasn't been met\")\n",
    "\n",
    "# Define stopping condition \n",
    "async def has_satisfied(trajectory, turn_counter):\n",
    "\n",
    "    structured_llm = model.with_structured_output(schema=Condition)\n",
    "    structured_system_prompt = \"\"\"Determine if the stopping condition was met from the following conversation history. \n",
    "    To meet the stopping condition, the conversation must follow one of the following scenarios: \n",
    "    1. All inquiries are satisfied, and user confirms that there are no additional issues that the support agent can help the customer with. \n",
    "    2. Not all user inquiries are satisfied, but next steps are clear, and user confirms that are no other items that the agent can help with. \n",
    "\n",
    "    The conversation between the customer and the customer support assistant that you should analyze is as follows:\n",
    "    {conversation}\n",
    "    \"\"\"\n",
    "\n",
    "    parsed_info = structured_llm.invoke([SystemMessage(content=structured_system_prompt.format(conversation=trajectory))])\n",
    "\n",
    "    return parsed_info.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4c823f5-a903-4ab7-9df6-f5c0426da125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation \n",
    "simulator_result = await run_multiturn_simulation_async(\n",
    "    app=app,\n",
    "    user=user,\n",
    "    trajectory_evaluators=[satisfaction_evaluator_async, resolution_evaluator_async, professionalism_evaluator_async],\n",
    "    max_turns=10,\n",
    "    thread_id=thread[\"thread_id\"], \n",
    "    stopping_condition=has_satisfied\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0adebbf-8c33-42c2-ae60-2f8314b180aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_turns = (len(simulator_result[\"trajectory\"])/2)\n",
    "num_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8deab2d4-8189-481a-ad29-2a057e56c5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'satisfaction', 'score': True, 'comment': \"The user initiated a refund request due to dissatisfaction with their purchase but actively engaged with the assistant to provide necessary information. After confirming the refund process, the user expressed gratitude and appreciation for the assistant's help. This indicates a resolution to their initial concern. Thus, the score should be: true.\", 'metadata': None}\n",
      "{'key': 'resolution', 'score': True, 'comment': 'The user initially requested a refund for their recent purchase, and throughout the conversation, they provided the necessary details such as their customer ID. The assistant confirmed the refund process had been initiated and informed the user about the expected timeline for the refund to be processed. The user expressed gratitude at the end, indicating they were satisfied with the resolution. Thus, the score should be: true.', 'metadata': None}\n",
      "{'key': 'professionalism', 'score': True, 'comment': \"Throughout the conversation, the assistant maintained a professional tone by responding politely to the user's requests, asking for necessary information, and providing clear instructions about the refund process. Additionally, the assistant expressed willingness to help and kept the communication courteous and supportive. Thus, the score should be: true.\", 'metadata': None}\n"
     ]
    }
   ],
   "source": [
    "for e in simulator_result[\"evaluator_results\"]: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b791fc9c-1619-4c83-8d63-a15e6800ea00",
   "metadata": {},
   "source": [
    "### Building "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5573cb9-5b8d-4d3e-aa6d-18a356f741d2",
   "metadata": {},
   "source": [
    "#### Loading sample customer data\n",
    "\n",
    "The agent utilizes the [Chinook database](https://www.sqlitetutorial.net/sqlite-sample-database/), which contains sample information on customer information, purchase history, and music catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a445b640-eb16-4b9c-adb8-ff09d96eb478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.pool import StaticPool\n",
    "\n",
    "def get_engine_for_chinook_db():\n",
    "    \"\"\"Pull sql file, populate in-memory database, and create engine.\"\"\"\n",
    "    url = \"https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\"\n",
    "    response = requests.get(url)\n",
    "    sql_script = response.text\n",
    "\n",
    "    connection = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "    connection.executescript(sql_script)\n",
    "    return create_engine(\n",
    "        \"sqlite://\",\n",
    "        creator=lambda: connection,\n",
    "        poolclass=StaticPool,\n",
    "        connect_args={\"check_same_thread\": False},\n",
    "    )\n",
    "\n",
    "engine = get_engine_for_chinook_db()\n",
    "db = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e0d63-2dec-4b63-bb1b-7e4e1233a303",
   "metadata": {},
   "source": [
    "#### Tools\n",
    "We create a list of tools for our example agent, giving it capabilities to fetch invoice and customer-related information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d35e02-a821-469d-96e5-478f1d48540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Optional\n",
    "\n",
    "@tool \n",
    "def get_invoices_by_customer_sorted_by_date(customer_id: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Look up all invoices for a customer using their ID.\n",
    "    The invoices are sorted in descending order by invoice date, which helps when the customer wants to view their most recent/oldest invoice, or if \n",
    "    they want to view invoices within a specific date range.\n",
    "    \n",
    "    Args:\n",
    "        customer_id (str): customer_id, which serves as the identifier.\n",
    "    \n",
    "    Returns:\n",
    "        list[dict]: A list of invoices for the customer.\n",
    "    \"\"\"\n",
    "    return db.run(f\"SELECT * FROM Invoice WHERE CustomerId = {customer_id} ORDER BY InvoiceDate DESC;\")\n",
    "\n",
    "\n",
    "@tool \n",
    "def get_invoices_sorted_by_unit_price(customer_id: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Use this tool when the customer wants to know the details of one of their invoices based on the unit price/cost of the invoice.\n",
    "    This tool looks up all invoices for a customer, and sorts the unit price from highest to lowest. In order to find the invoice associated with the customer, \n",
    "    we need to know the customer ID.\n",
    "    \n",
    "    Args:\n",
    "        customer_id (str): customer_id, which serves as the identifier.\n",
    "    \n",
    "    Returns:\n",
    "        list[dict]: A list of invoices sorted by unit price.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT Invoice.*, InvoiceLine.UnitPrice\n",
    "        FROM Invoice\n",
    "        JOIN InvoiceLine ON Invoice.InvoiceId = InvoiceLine.InvoiceId\n",
    "        WHERE Invoice.CustomerId = {customer_id}\n",
    "        ORDER BY InvoiceLine.UnitPrice DESC;\n",
    "    \"\"\"\n",
    "    return db.run(query)\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_employee_by_invoice_and_customer(invoice_id: str, customer_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    This tool will take in an invoice ID and a customer ID and return the employee information associated with the invoice.\n",
    "\n",
    "    Args:\n",
    "        invoice_id (int): The ID of the specific invoice.\n",
    "        customer_id (str): customer_id, which serves as the identifier.\n",
    "\n",
    "    Returns:\n",
    "        dict: Information about the employee associated with the invoice.\n",
    "    \"\"\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT Employee.FirstName, Employee.Title, Employee.Email\n",
    "        FROM Employee\n",
    "        JOIN Customer ON Customer.SupportRepId = Employee.EmployeeId\n",
    "        JOIN Invoice ON Invoice.CustomerId = Customer.CustomerId\n",
    "        WHERE Invoice.InvoiceId = ({invoice_id}) AND Invoice.CustomerId = ({customer_id});\n",
    "    \"\"\"\n",
    "    \n",
    "    employee_info = db.run(query, include_columns=True)\n",
    "    \n",
    "    if not employee_info:\n",
    "        return f\"No employee found for invoice ID {invoice_id} and customer identifier {customer_id}.\"\n",
    "    return employee_info\n",
    "\n",
    "\n",
    "@tool \n",
    "def refund_invoice(invoice_id: str, customer_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Handles refund for invoices. Certain criteria must be checked for a invoice to be refunded before invoking this tool, \n",
    "    such as whether the customer has a valid reason for refund. \n",
    "    \n",
    "    Args:\n",
    "        invoice_id (str): invoice_id\n",
    "        customer_id (str): ID of the customer\n",
    "    \n",
    "    Returns:\n",
    "        dict: Status of refund\n",
    "    \"\"\"\n",
    "\n",
    "    # dummy tool\n",
    "    return f\"Invoice {invoice_id} has been refunded.\"\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def update_customer_info(identifier: str, updates: dict):\n",
    "    \"\"\"\n",
    "    Update a specific field(s) of a customer's record in the database.\n",
    "    If the customer wants to update their address, city, state, country, or postal code, \n",
    "    make sure to ask them for the full address (street, city, state, country, and postal code).\n",
    "    Do not make up the other fields. Get all of the fields from the customer associated with their new location and then update all of the fields in the database.\n",
    "\n",
    "    Args:\n",
    "        identifier (str): The customer identifier can be customer ID, email, or phone.\n",
    "        updates (dict): A dictionary of field names and their corresponding new values. For example: {\"Address\": \"594 Broadway\", \"City\": \"New York\", \"State\": \"NY\", \"Country\": \"USA\", \"PostalCode\": \"10016\"}\n",
    "\n",
    "    Returns:\n",
    "        str: Success message or error message.\n",
    "    \"\"\"\n",
    "    customer_id = get_customer_id_from_identifier(identifier)\n",
    "\n",
    "    # Simple implementation \n",
    "    return f\"Successfully updated for customer with identifier: {identifier}\"\n",
    "\n",
    "customer_support_tools = [get_invoices_by_customer_sorted_by_date, get_invoices_sorted_by_unit_price, get_employee_by_invoice_and_customer, refund_invoice, update_customer_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30929e26-4492-4860-839e-747ce49c7acd",
   "metadata": {},
   "source": [
    "#### Prompt instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5110ed-65b3-44a9-9377-655bbfe76d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_PROMPT = \"\"\"\n",
    "    You are a customer support agent specialized for handling and processing invoice and customer information. \n",
    "    \n",
    "    If you need additional information, such as customer id, to retrieve the invoice or account information, \n",
    "    inform the customer you are unable to retrieve the information, and ask for any needed info.\n",
    "\n",
    "    Before ending a conversation, always ask the customer if there are additional issues or items that you can help with.\n",
    "\n",
    "    \n",
    "    CORE RESPONSIBILITIES:\n",
    "    - Retrieve and process invoice information from the database\n",
    "    - Provide detailed information including customer details, invoice dates, total amounts, employees associated, when the customer asks for it.\n",
    "    - Always maintain a professional, friendly, and patient demeanor\n",
    "    \n",
    "    You may have additional conversation history that you should use to help answer the customer's query. It will be provided to you. \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a5a80-995e-44ba-9e03-02be07056ca0",
   "metadata": {},
   "source": [
    "#### Create simple react agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c0d187-5831-42b0-a15b-a9fac08100e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"o3-mini\")\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "\n",
    "# Define the agent \n",
    "customer_support_agent = create_react_agent(\n",
    "    model,\n",
    "    tools = customer_support_tools,\n",
    "    prompt=AGENT_PROMPT,\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# Visualize the graph\n",
    "display(Image(customer_support_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924178cf-d978-49d0-9940-9f97974f7263",
   "metadata": {},
   "source": [
    "### Running multi-turn evaluation \n",
    "We will add a stopping condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b418640a-f6bd-47cc-bd2b-675bacf0c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def app(inputs, thread_id):\n",
    "    result = customer_support_agent.invoke(\n",
    "        {\"messages\": [inputs]}, \n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    return result[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5a690-d6e3-46f0-aa71-4a94839aa0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openevals.llm import create_llm_as_judge\n",
    "\n",
    "\n",
    "# Create evaluators \n",
    "satisfaction_evaluator = create_llm_as_judge(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    prompt=\"Based on the below conversation, is the user satisfied?\\n{outputs}\",\n",
    "    feedback_key=\"satisfaction\",\n",
    ")\n",
    "\n",
    "resolution_evaluator = create_llm_as_judge(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    prompt=\"Based on the below conversation, is the user request resolved?\\n{outputs}\",\n",
    "    feedback_key=\"resolution\",\n",
    ")\n",
    "\n",
    "professionalism_evaluator = create_llm_as_judge(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    prompt=\"Based on the below conversation, has our agent remained a professional tone throughout the conversation?\\n{outputs}\",\n",
    "    feedback_key=\"professionalism\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0dbe5a-76fc-4d17-b875-ad47a7460007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from openevals.simulators import run_multiturn_simulation, create_llm_simulated_user\n",
    "\n",
    "thread_id = uuid.uuid4()\n",
    "\n",
    "# Create user persona\n",
    "multiple_question_user = create_llm_simulated_user(\n",
    "    system=\"\"\"You are a user talking to the customer support, your account ID is 1. \n",
    "    Your request is wanting to understand the employee who helped you with the \n",
    "    most recent invoice. \"\"\",\n",
    "    model=\"openai:gpt-4.1-nano\",\n",
    ")\n",
    "\n",
    "\n",
    "# Create simulator \n",
    "simulator_result = run_multiturn_simulation(\n",
    "    app=app,\n",
    "    user=multiple_question_user,\n",
    "    trajectory_evaluators=[satisfaction_evaluator, resolution_evaluator, professionalism_evaluator],\n",
    "    max_turns=10,\n",
    "    thread_id=thread_id, \n",
    "    stopping_condition=has_satisfied\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f6f382-4581-4846-91e6-a5ba12d2e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_turns = (len(simulator_result[\"trajectory\"])/2)\n",
    "num_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392b395-c3c0-415e-a291-0233e9436532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages.utils import convert_to_messages\n",
    "\n",
    "messages = convert_to_messages(simulator_result[\"trajectory\"])\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a74261-9ce3-479e-80df-1677f25a15b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in simulator_result[\"evaluator_results\"]: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f643f-ea39-4293-972a-887d12998f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
